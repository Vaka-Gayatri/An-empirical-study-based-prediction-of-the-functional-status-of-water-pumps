{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xL7aUTXp5yTa"
   },
   "source": [
    "<h1 id=\"An-empirical-study-based-prediction-of-the-functional-status-of-water-pumps\" style=\"font-size: 32px; font-family: sans-serif; line-height: 1; margin: 0.4em 0.2em 0.3em; color: #126dce; padding-left: 80px; text-align: center;\"><span style=\"color: #236fa1;\"><strong>An empirical study based prediction of </strong></span><span style=\"color: #236fa1;\"><strong>the functional status of water pumps</strong></span></h1>\n",
    "<h3 id=\"A-machine-learning-approach-to-predict-the-water-pump's-state-\" style=\"font-family: sans-serif; line-height: 1; font-size: 22.4px; color: #126dce; margin: 0.4em 0.2em 0.3em; text-align: center;\"><span style=\"color: #000000;\">A machine learning approach to predict the water pump's state </span></h3>\n",
    "<h3 id=\"based-on-the-survey-data-made-available-by-Tanzanian-Government\" style=\"font-family: sans-serif; line-height: 1; font-size: 22.4px; color: #126dce; margin: 0.4em 0.2em 0.3em; text-align: center;\"><span style=\"color: #000000;\">based on the survey data made available by Tanzanian Government</span></h3>\n",
    "<p style=\"text-align: center;\">&nbsp;</p>\n",
    "<p style=\"text-align: center;\"><strong style=\"font-size: 16px;\">Team Details</strong></p>\n",
    "<p style=\"text-align: center;\"><span style=\"color: #000000; font-size: 12pt;\">Rajesh Anumula</span></p>\n",
    "<p style=\"text-align: center;\"><span style=\"color: #000000; font-size: 12pt;\">Bhavana Chowdhary Dodda</span></p>\n",
    "<p style=\"text-align: center;\"><span style=\"color: #000000; font-size: 12pt;\">Gayatri Waka</span></p>\n",
    "<p style=\"text-align: center;\"><span style=\"color: #000000; font-size: 12pt;\">Pranav V. Kamble</span></p>\n",
    "<p style=\"text-align: center;\">&nbsp;</p>\n",
    "<p style=\"text-align: center;\"><span style=\"font-size: 12pt;\">Under the guidance of</span></p>\n",
    "<p style=\"text-align: center;\"><span style=\"font-size: 12pt;\"><strong>Dr. Atif Farid Mohammad</strong></span></p>\n",
    "<p style=\"text-align: center;\">&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47yrH-4g5yTb"
   },
   "source": [
    "<h4 id=\"Introduction\" style=\"text-align: justify;\"><span style=\"color: #236fa1;\"><strong>Introduction</strong></span></h4>\n",
    "<p style=\"text-align: justify;\"><span style=\"font-size: 16px;\">We are working on the empirical data gathered and made available by the Tanzanian Government as a result of a nationwide survey of water pumps and their natural sources. The goal of this project is to predict the status of the water pumps based on various data points gathered in the survey. By examining the data, the status can be <strong><em>functional, non-functional or functional but needs repair.</em></strong></span></p>\n",
    "<p style=\"text-align: justify;\"><span style=\"font-size: 16px;\">The primary objective of the problem statement is to identify the water pumps that need attention can be given the priority to service them to ensure that there is enough water availability across Tanzania</span></p>\n",
    "<p style=\"text-align: justify;\">&nbsp;</p>\n",
    "<p style=\"text-align: justify;\"><span style=\"font-size: 16px;\">With the enormous capabilities that the field of machine learning provides, the possibilities that this field works with are limitless. It is of utmost importance to know how to best make use of the techniques that suit you the most. With this project, we aim to get an idea of working through the entire machine learning pipeline and try various supervised machine learning techniques.&nbsp;</span></p>\n",
    "<p style=\"text-align: justify;\">&nbsp;</p>\n",
    "<p style=\"text-align: justify;\"><span style=\"font-size: 12pt;\">This project is our effort to learn machine learning techniques right from analyzing the data to running a few machine learning algorithms to better get a good understanding of the concepts.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 id=\"Dataset-Description\"><span style=\"color: #236fa1;\"><strong>Dataset Description</strong></span></h4>\n",
    "<p><span style=\"font-size: 12pt;\">The dataset is a combination of categorical and numerical features. There is a total of 39 attributes in the dataset.&nbsp;</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><span style=\"font-size: 12pt;\">1. amount_tsh: Amount of water available to the waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">2. date_recorded: Date of entry.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">3. funder: Person who funded the well.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">4. gps_height: Altitude of the well.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">5. installer: Organization that installed the well.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">6. longitude: GPS Longitudinal coordinate.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">7. latitude: GPS Latitudinal coordinate.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">8. wpt_name: Name of the waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">9. num_private: Private number.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">10. basin: Geographic water basin.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">11. subvillage: Geographic location.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">12. region: Geographic location.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">13. region_code: Geographic location code.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">14. district_code: Geographic location code.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">15. lga: Geographic location.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">16. ward: Geographic location.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">17. population: Population around the well.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">18. public_meeting: True/False.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">19. recorded_by: Person entering the data.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">20. scheme_management: One who operates the waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">21. scheme_name: Who operates the waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">22. permit: If a permit exists for the waterpoint or not.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">23. construction_year: Year of construction of the waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">24. extraction_type: Kind of extraction that the waterpoint uses.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">25. extraction_type_group: Kind of extraction that the waterpoint uses.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">26. extraction_type_class: Kind of extraction that the waterpoint uses.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">27. management: How the waterpoint is managed.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">28. management_group: How the waterpoint is managed.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">29. payment: What the water costs.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">30. payment_type: What the water costs.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">31. water_quality: Quality of the water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">32. quality_group: The quality of the water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">33. quantity: The quantity of water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">34. quantity_group: The quantity of water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">35. source: Source of water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">36. source_type: The source of water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">37. source_class: The source of water.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">38. waterpoint_type: The kind of waterpoint.</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">39. waterpoint_type_group: The kind of waterpoint.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><strong style=\"color: #236fa1; font-family: 'helvetica neue', helvetica, arial, sans-serif; font-size: 17px;\">Data analysis</strong></p>\n",
    "<p><span style=\"font-size: 12pt;\">We analyzed data for the skewness of the output class in the training set. The dataset is fairly distributed for the classes we are designating the data to. Below are the numbers -</span></p>\n",
    "<p><span style=\"font-size: 16px;\">Functional: 32259</span></p>\n",
    "<p><span style=\"font-size: 16px;\">Non-functional: 22824</span></p>\n",
    "<p><span style=\"font-size: 16px;\">Functional but needs repair: 4317</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><span style=\"font-size: 16px;\">Total number of instances: 59400</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 id=\"Feature-Selection-Strategy\" style=\"font-family: 'helvetica neue' , 'helvetica' , 'arial' , sans-serif; color: #000000;\"><span style=\"color: #236fa1;\"><strong>Feature Selection Strategy</strong></span></h4>\n",
    "<p><span style=\"font-size: 12pt;\">While analyzing the dataset, we <strong>removed</strong> the attributes that showed below traits -</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><strong><span style=\"font-size: 12pt;\">1. Redundancy</span></strong></p>\n",
    "<p><span style=\"font-size: 12pt;\">There are a few attributes that are repeatative and are only for providing more information about the other columns. For example, '<strong>waterpoint_type</strong>' and '<strong>waterpoint_type_group</strong>'. Another such example is '<strong>quantity</strong>' and '<strong>quantity_group</strong>'.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 id=\"2.-Geographical-metadata\" style=\"font-family: 'helvetica neue' , 'helvetica' , 'arial' , sans-serif; color: #000000;\"><span style=\"font-size: 12pt;\"><strong>2. Geographical metadata</strong></span></h4>\n",
    "<p><span style=\"font-size: 12pt;\">We already have the geographical coordinates of the wells given by '<strong>latitude</strong>' and '<strong>longitude</strong>' attributes. Hence, the geographical data that gives more information about the geography around the water source is not necessary. The coordinates along with the '<strong>gps_height</strong>' attribute give enough information that will be necessary for determination.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><span style=\"font-size: 12pt;\"><strong>3. Survey information</strong></span></p>\n",
    "<p><span style=\"font-size: 12pt;\">We also do not need the attributes which provide more information regarding the survey. For example, '<strong>wpt_name</strong>' provides the name of the water point, '<strong>recorded_by</strong>' gives the surveyor's name and many more. These attributes do not contribute to the determination directly.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><strong><span style=\"font-size: 12pt;\">4. Attributes that are skewed heavily</span></strong></p>\n",
    "<p><span style=\"font-size: 12pt;\">This can happen if the majority of the attribute data has only one value. One such attribute is </span><span style=\"font-size: 16px;\">&nbsp;</span><span style=\"font-size: 16px;\">'<strong>recorded_by</strong>' which has the same value for all entries.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 id=\"Data-preprocessing\" style=\"font-family: 'helvetica neue' , 'helvetica' , 'arial' , sans-serif; color: #000000;\"><span style=\"color: #236fa1;\"><strong>Data preprocessing</strong></span></h4>\n",
    "<p><strong><span style=\"font-size: 12pt;\">1. Combination</span></strong></p>\n",
    "<p><span style=\"font-size: 12pt;\">Combining a few attributes will reduce the columns as well as improve the contribution to the inference. We are combing columns '<strong>date_recorded</strong>' and '<strong>construction_year</strong>' to form a new <strong>'age'&nbsp;</strong>attribute.</span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p><span style=\"font-size: 12pt;\"><strong style=\"font-size: 13px;\"><span style=\"font-size: 12pt;\">2. Remove rows with missing data</span></strong></span></p>\n",
    "<p><span style=\"font-size: 12pt;\"><span style=\"font-size: 12pt;\">We are removing the rows that have missing/partial data. The number of such rows is less and hence removing them will not impact the overall model.</span></span></p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 id=\"Code-In-Action\" style=\"font-family: 'helvetica neue' , 'helvetica' , 'arial' , sans-serif; color: #000000;\"><span style=\"color: #236fa1;\"><strong>Code In Action</strong></span></h4>\n",
    "<p><span style=\"font-size: 12pt;\">The below section is the python code that we tried out. We are using below python libraries -</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">1.&nbsp;<strong>Pandas</strong>&nbsp;- for easy data manipulation</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">2.&nbsp;<strong>SciKit Learn</strong>&nbsp;- for seamless use of machine learning algorithms</span></p>\n",
    "<p><span style=\"font-size: 12pt;\">3. Category Encoders - for converting categorical data to numerical data</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GP0Ejcd95yTc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-03b8f29b2bb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(file_values,file_labels):\n",
    "    # set all the column names for training_data set\n",
    "    names1 = ['id','amount_tsh','date_recorded','funder','gps_height','installer','longitude','latitude','wpt_name',\n",
    "              'num_private','basin','subvillage','region','region_code','district_code','lga','ward','population',\n",
    "              'public_meeting','recorded_by','scheme_management','scheme_name','permit','construction_year',\n",
    "              'extraction_type','extraction_type_group','extraction_type_class','management','management_group',\n",
    "              'payment','payment_type','water_quality','quality_group','quantity','quantity_group','source','source_type',\n",
    "              'source_class','waterpoint_type','waterpoint_type_group']\n",
    "    \n",
    "    # set all the column names for labels set\n",
    "    names2 = ['id', 'status_group']\n",
    "\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    file_values = pandas.read_csv(file_values,names=names1)\n",
    "    file_labels = pandas.read_csv(file_labels,names=names2)\n",
    "        \n",
    "    # X_raw is data combining both values and labels for further preprocessing\n",
    "    X_raw = pandas.concat([file_values, file_labels], axis=1)\n",
    "    X_raw.drop(X_raw.index[0], inplace=True)\n",
    "\n",
    "    return X_raw\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # remove rows with blank cells for some of the features\n",
    "    df['funder'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['funder'], inplace=True)\n",
    "    \n",
    "    df['public_meeting'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['public_meeting'], inplace=True)\n",
    "    \n",
    "    df['scheme_management'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['scheme_management'], inplace=True)\n",
    "    \n",
    "    df['permit'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['permit'], inplace=True)\n",
    "    \n",
    "def combine_columns(df):\n",
    "    #Replace empty data with None value\n",
    "    df['date_recorded'].replace('', np.nan, inplace=True)\n",
    "    df['construction_year'] = df['construction_year'].astype('int32')\n",
    "    df['construction_year'].replace(0,np.nan,inplace=True)\n",
    "    \n",
    "    #Remove the rows with None values\n",
    "    df.dropna(subset=['date_recorded'], inplace=True)\n",
    "    df.dropna(subset=['construction_year'],inplace=True)\n",
    "    \n",
    "    #Extract the year of recorded date\n",
    "    df['date_recorded'] = pandas.to_datetime(df['date_recorded']).dt.year\n",
    "    \n",
    "    #Convert year to int\n",
    "    df['date_recorded'] = df['date_recorded'].astype('int32')\n",
    "    \n",
    "    #Substitute value --> The calculated value is the age of the pump\n",
    "    df['date_recorded'] = df['date_recorded']- df['construction_year']\n",
    "    return df\n",
    "    \n",
    "def remove_reduntent_features(x):\n",
    "    # drop redundant features\n",
    "    x.drop(x.columns[[0,8,9,11,12,13,14,15,16,19,21,23,25,26,28,30,34,36,37,39]], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "def category_to_numeric(x):\n",
    "    x.dropna(inplace=True)\n",
    "    # transform categorical variables to numeric\n",
    "    encoder = ce.OrdinalEncoder(cols=['status_group'])\n",
    "    x = encoder.fit_transform(x)\n",
    "    x = x.apply(pandas.to_numeric, errors='ignore')\n",
    "    encoder = ce.BinaryEncoder()\n",
    "    x = encoder.fit_transform(x)\n",
    "    x = x.replace([np.inf, -np.inf], np.nan)\n",
    "    x = x.dropna()\n",
    "    return x\n",
    "\n",
    "def extract_x_y(df):\n",
    "    arr = df.values\n",
    "    x = arr[:,:-1]\n",
    "    y = arr[:,-1]\n",
    "    \n",
    "    return x , y\n",
    "\n",
    "def get_accuracy(model,dataset_X,dataset_Y):\n",
    "    seed = 11\n",
    "    k=15\n",
    "    kFold = model_selection.KFold(n_splits=k, random_state=seed)\n",
    "    \n",
    "    #cross_val_score splits the dataset into training and testing dataset\n",
    "    result = model_selection.cross_val_score(model, X, Y, cv=kFold)\n",
    "    #return the mean accuracy score\n",
    "    return result.mean()*100\n",
    "\n",
    "\n",
    "### Load datasets and perform all data cleaning and combining operations\n",
    "data = load_dataset('Training_set_values.csv','Training_set_labels.csv')\n",
    "\n",
    "preprocess_data(data)\n",
    "data = combine_columns(data)\n",
    "remove_reduntent_features(data)\n",
    "\n",
    "data_c_n = category_to_numeric(data)\n",
    "\n",
    "X, Y = extract_x_y(data_c_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1KREVYF5yTg"
   },
   "source": [
    "<h4 style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; margin: 0.4em 0.2em 0.3em !important;\"><span style=\"color: #353535; font-family: sans-serif; font-size: 16px;\">Now the data has been set up, let's try different models and check their accuracy.</span></h4>\n",
    "<h4 style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; margin: 0.4em 0.2em 0.3em !important;\">&nbsp;</h4>\n",
    "<h4 id=\"Code-In-Action\" style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; margin: 0.4em 0.2em 0.3em !important;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #236fa1;\"><strong>Random Forest</strong></span></h4>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #353535; font-family: sans-serif; font-size: 16px;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; font-size: 12pt;\">Random forest is an ensemble learning method. It is a powerful method that uses multiple decision trees that are the best classifiers. This is one of the most accurate classifiers available.</span></p>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #353535; font-family: sans-serif; font-size: 16px;\">More information about usage can be found at - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</p>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #353535; font-family: sans-serif; font-size: 16px;\">&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-EK260o5yTh",
    "outputId": "1137a1ce-793d-41d8-fbec-547ae1ddbfa2"
   },
   "outputs": [],
   "source": [
    "# run random forest algorithm\n",
    "print(\"Random Forest Algorithm -\")\n",
    "seed = 11\n",
    "num_trees = 100\n",
    "max_features = 15\n",
    "# k=15\n",
    "# kFold = model_selection.KFold(n_splits=k, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "accuracy_RF = get_accuracy(model,X,Y)\n",
    "print(\"%.2f\"%accuracy_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EE5ud0uZ5yTq"
   },
   "source": [
    "<p>&nbsp;</p>\n",
    "<h4 id=\"Code-In-Action\" style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; margin: 0.4em 0.2em 0.3em !important;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #236fa1;\"><strong>Logistic Regression</strong></span></h4>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"color: #353535; font-family: sans-serif;\"><span style=\"font-size: 16px;\">Logistic Regression is a type of classifier that predicts the probabilities of different possible outcomes of the categorical response variable.</span></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkIw5XXd5yTq",
    "outputId": "cae14010-d40b-48ca-d11c-0eec253dabbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression algorithm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d6c01deb7c27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run Logistic Regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression algorithm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodelLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maccuracy_LR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelLR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%.2f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0maccuracy_LR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Run Logistic Regression\n",
    "print(\"Logistic Regression algorithm\")\n",
    "modelLR = LogisticRegression()\n",
    "accuracy_LR = get_accuracy(modelLR,X,Y)\n",
    "print(\"%.2f\"%accuracy_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0IfeYLj5yTu"
   },
   "source": [
    "<h4 id=\"Logistic-Regression\" style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; margin: 0.4em 0.2em 0.3em; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #236fa1;\"><strong>AdaBoost</strong></span></h4>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #353535; font-family: sans-serif; font-size: 16px;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\">Adaboost or Adaptive boosting is a very effective technique of combining several weak classifiers to produce an overall strong classifier.</span></p>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"color: #353535; font-family: sans-serif;\"><span style=\"font-size: 16px;\">The advantage of Adaboost is that it works well with both basic and complex problems. It produces a highly accurate classifier using a series of weak classifiers (the result of the first weak classifier is fed to the second weak classifier and so on.)</span></span></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmgUeQ9A5yTv",
    "outputId": "a57d702f-99ef-4c13-ea76-ffe30a5f7fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost algorithm\n",
      "72.02\n"
     ]
    }
   ],
   "source": [
    "# Run AdaBoost\n",
    "print(\"Ada Boost algorithm\")\n",
    "seed = 11\n",
    "num_trees = 100\n",
    "modelAB = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "accuracy_AB = get_accuracy(modelAB, X, Y)\n",
    "print(\"%.2f\"%accuracy_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dh2NFAeH5yTy"
   },
   "source": [
    "<h4 id=\"AdaBoost\" style=\"font-family: 'helvetica neue', helvetica, arial, sans-serif; line-height: 1; color: #000000; margin: 0.4em 0.2em 0.3em; font-size: 17.6px; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased; color: #236fa1;\"><strong>Deep learning</strong></span></h4>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"color: #353535; font-family: sans-serif;\"><span style=\"font-size: 16px;\">Deep Learning is a branch of Machine Learning that models data abstraction by employing a deep graph with usually many layers of linear and non-linear transformations.</span></span></p>\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 0.5em; text-rendering: geometricprecision; -webkit-font-smoothing: subpixel-antialiased;\"><span style=\"color: #353535; font-family: sans-serif;\"><span style=\"font-size: 16px;\">One big advantage of deep learning is that we can help build a complex classifier without using or needing too many features.</span></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0orFfV_C5yTz",
    "outputId": "c184e261-4f46-429c-c2cd-0f89d8db524a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep learning algorithm\n"
     ]
    }
   ],
   "source": [
    "# Run deep learning\n",
    "print(\"deep learning algorithm\")\n",
    "modelDL = MLPClassifier(hidden_layer_sizes=(98, 50), learning_rate_init=0.01)\n",
    "accuracy_DL = get_accuracy(modelDL,X,Y)\n",
    "print(\"%.2f\"%accuracy_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUFbqKk85yT4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "project_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
